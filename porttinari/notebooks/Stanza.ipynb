{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lnr_HpghLhvf"
      },
      "source": [
        "# Stanza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4uLMklaLjpr"
      },
      "source": [
        "## Setting up Stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaWgX8uxTAlw",
        "outputId": "834eef94-5b6e-4f05-e399-274c00116b84"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/huberemanuel/stanza-train-br.git\n",
        "! cd stanza-train-br && git clone https://github.com/huberemanuel/stanza\n",
        "! pip install -r /content/stanza-train-br/requirements.txt\n",
        "! pip install -e /content/stanza-train-br/stanza\n",
        "! pip install pythainlp\n",
        "! cd /content/stanza-train-br/ && cp config/config.sh stanza/scripts/config.sh\n",
        "! cd /content/stanza-train-br/ && cp config/xpos_vocab_factory.py stanza/stanza/models/pos/xpos_vocab_factory.py\n",
        "! cd /content/stanza-train-br/ && make download_data\n",
        "! cd /content/stanza-train-br/ && make download_vectors_colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IiV6k57gYLG"
      },
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ewTKPL2iP-N",
        "outputId": "f8f1c769-72ce-4a33-dce2-98a40a3f3126"
      },
      "outputs": [],
      "source": [
        "! python3 -m stanza.utils.datasets.prepare_pos_treebank UD_Portuguese-Porttinari"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op4SHnlMXUlt",
        "outputId": "c3ec9874-bae3-4c82-b66a-2c3f4dbfc685"
      },
      "outputs": [],
      "source": [
        "%%writefile /content/stanza-train-br/stanza/stanza/utils/training/common.py\n",
        "import argparse\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import pathlib\n",
        "import sys\n",
        "import tempfile\n",
        "\n",
        "from enum import Enum\n",
        "\n",
        "from stanza.models.common.constant import treebank_to_short_name\n",
        "from stanza.resources.common import download, DEFAULT_MODEL_DIR\n",
        "from stanza.utils.datasets import common\n",
        "import stanza.utils.default_paths as default_paths\n",
        "from stanza.utils import conll18_ud_eval as ud_eval\n",
        "\n",
        "logger = logging.getLogger('stanza')\n",
        "\n",
        "class Mode(Enum):\n",
        "    TRAIN = 1\n",
        "    SCORE_DEV = 2\n",
        "    SCORE_TEST = 3\n",
        "    SCORE_TRAIN = 4\n",
        "\n",
        "BERT = {\n",
        "    # https://huggingface.co/Maltehb/danish-bert-botxo\n",
        "    # contrary to normal expectations, this hurts F1\n",
        "    # on a dev split by about 1 F1\n",
        "    # \"da\": \"Maltehb/danish-bert-botxo\",\n",
        "    #\n",
        "    # the multilingual bert is a marginal improvement for conparse\n",
        "    \"da\": \"bert-base-multilingual-cased\",\n",
        "\n",
        "    # https://huggingface.co/roberta-base\n",
        "    \"en\": \"roberta-base\",\n",
        "\n",
        "    # NER scores for a couple options:\n",
        "    # none:\n",
        "    # dev:  2022-03-04 INFO: fi_turku 83.45\n",
        "    # test: 2022-03-04 INFO: fi_turku 86.25\n",
        "    #\n",
        "    # bert-base-multilingual-cased\n",
        "    # dev:  2022-03-04 INFO: fi_turku 85.23\n",
        "    # test: 2022-03-04 INFO: fi_turku 89.00\n",
        "    #\n",
        "    # TurkuNLP/bert-base-finnish-cased-v1:\n",
        "    # dev:  2022-03-04 INFO: fi_turku 88.41\n",
        "    # test: 2022-03-04 INFO: fi_turku 91.36\n",
        "    \"fi\": \"TurkuNLP/bert-base-finnish-cased-v1\",\n",
        "\n",
        "    # from https://github.com/idb-ita/GilBERTo\n",
        "    # annoyingly, it doesn't handle cased text\n",
        "    # supposedly there is an argument \"do_lower_case\"\n",
        "    # but that still leaves a lot of unk tokens\n",
        "    # \"it\": \"idb-ita/gilberto-uncased-from-camembert\",\n",
        "    #\n",
        "    # from https://github.com/musixmatchresearch/umberto\n",
        "    # on NER, this gets 88.37 dev and 91.02 test\n",
        "    # another option is dbmdz/bert-base-italian-cased,\n",
        "    # which gets 87.27 dev and 90.32 test\n",
        "    \"it\": \"Musixmatch/umberto-commoncrawl-cased-v1\",\n",
        "\n",
        "    # experiments on the cintil conparse dataset\n",
        "    # ran a variety of transformer settings\n",
        "    # found the following dev set scores after 400 iterations:\n",
        "    # Geotrend/distilbert-base-pt-cased : not plug & play\n",
        "    # no bert: 0.9082\n",
        "    # xlm-roberta-base: 0.9109\n",
        "    # xlm-roberta-large: 0.9254\n",
        "    # adalbertojunior/distilbert-portuguese-cased: 0.9300\n",
        "    # neuralmind/bert-base-portuguese-cased: 0.9307\n",
        "    # neuralmind/bert-large-portuguese-cased: 0.9343\n",
        "    \"pt\": \"neuralmind/bert-large-portuguese-cased\",\n",
        "\n",
        "    # https://huggingface.co/dbmdz/bert-base-turkish-128k-cased\n",
        "    # helps the Turkish model quite a bit\n",
        "    \"tr\": \"dbmdz/bert-base-turkish-128k-cased\",\n",
        "\n",
        "    # from https://github.com/VinAIResearch/PhoBERT\n",
        "    # \"vi\": \"vinai/phobert-base\",\n",
        "    # another option is phobert-large, but that doesn't\n",
        "    # change the scores any\n",
        "    \"vi\": \"vinai/phobert-large\",\n",
        "\n",
        "    # https://github.com/ymcui/Chinese-BERT-wwm\n",
        "    # there's also hfl/chinese-roberta-wwm-ext-large\n",
        "    \"zh-hans\": \"hfl/chinese-roberta-wwm-ext\",\n",
        "}\n",
        "\n",
        "def build_argparse():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--save_output', dest='temp_output', default=True, action='store_false', help=\"Save output - default is to use a temp directory.\")\n",
        "\n",
        "    parser.add_argument('treebanks', type=str, nargs='+', help='Which treebanks to run on.  Use all_ud or ud_all for all UD treebanks')\n",
        "\n",
        "    parser.add_argument('--train', dest='mode', default=Mode.TRAIN, action='store_const', const=Mode.TRAIN, help='Run in train mode')\n",
        "    parser.add_argument('--score_dev', dest='mode', action='store_const', const=Mode.SCORE_DEV, help='Score the dev set')\n",
        "    parser.add_argument('--score_test', dest='mode', action='store_const', const=Mode.SCORE_TEST, help='Score the test set')\n",
        "    parser.add_argument(\"--score_train\", dest=\"mode\", action=\"store_const\", const=Mode.SCORE_TRAIN, help=\"Score the train set\")\n",
        "\n",
        "    # This argument needs to be here so we can identify if the model already exists in the user-specified home\n",
        "    parser.add_argument('--save_dir', type=str, default=None, help=\"Root dir for saving models.  If set, will override the model's default.\")\n",
        "\n",
        "    parser.add_argument('--force', dest='force', action='store_true', default=False, help='Retrain existing models')\n",
        "    return parser\n",
        "\n",
        "def main(run_treebank, model_dir, model_name, add_specific_args=None):\n",
        "    \"\"\"\n",
        "    A main program for each of the run_xyz scripts\n",
        "\n",
        "    It collects the arguments and runs the main method for each dataset provided.\n",
        "    It also tries to look for an existing model and not overwrite it unless --force is provided\n",
        "\n",
        "    model_name can be a callable expecting the args\n",
        "      - the charlm, for example, needs this feature, since it makes\n",
        "        both forward and backward models\n",
        "    \"\"\"\n",
        "    logger.info(\"Training program called with:\\n\" + \" \".join(sys.argv))\n",
        "\n",
        "    paths = default_paths.get_default_paths()\n",
        "\n",
        "    parser = build_argparse()\n",
        "    if add_specific_args is not None:\n",
        "        add_specific_args(parser)\n",
        "    if '--extra_args' in sys.argv:\n",
        "        idx = sys.argv.index('--extra_args')\n",
        "        extra_args = sys.argv[idx+1:]\n",
        "        command_args = parser.parse_args(sys.argv[1:idx])\n",
        "    else:\n",
        "        command_args, extra_args = parser.parse_known_args()\n",
        "\n",
        "    # Pass this through to the underlying model as well as use it here\n",
        "    if command_args.save_dir:\n",
        "        extra_args.extend([\"--save_dir\", command_args.save_dir])\n",
        "\n",
        "    if callable(model_name):\n",
        "        model_name = model_name(command_args)\n",
        "\n",
        "    mode = command_args.mode\n",
        "    treebanks = []\n",
        "\n",
        "    for treebank in command_args.treebanks:\n",
        "        # this is a really annoying typo to make if you copy/paste a\n",
        "        # UD directory name on the cluster and your job dies 30s after\n",
        "        # being queued for an hour\n",
        "        if treebank.endswith(\"/\"):\n",
        "            treebank = treebank[:-1]\n",
        "        if treebank.lower() in ('ud_all', 'all_ud'):\n",
        "            ud_treebanks = common.get_ud_treebanks(paths[\"UDBASE\"])\n",
        "            treebanks.extend(ud_treebanks)\n",
        "        else:\n",
        "            treebanks.append(treebank)\n",
        "\n",
        "    for treebank_idx, treebank in enumerate(treebanks):\n",
        "        if treebank_idx > 0:\n",
        "            logger.info(\"=========================================\")\n",
        "\n",
        "        short_name = treebank_to_short_name(treebank)\n",
        "        logger.debug(\"%s: %s\" % (treebank, short_name))\n",
        "\n",
        "        if mode == Mode.TRAIN and not command_args.force and model_name != 'ete':\n",
        "            if command_args.save_dir:\n",
        "                model_path = \"%s/%s_%s.pt\" % (command_args.save_dir, short_name, model_name)\n",
        "            else:\n",
        "                model_path = \"saved_models/%s/%s_%s.pt\" % (model_dir, short_name, model_name)\n",
        "            if os.path.exists(model_path):\n",
        "                logger.info(\"%s: %s exists, skipping!\" % (treebank, model_path))\n",
        "                continue\n",
        "            else:\n",
        "                logger.info(\"%s: %s does not exist, training new model\" % (treebank, model_path))\n",
        "\n",
        "        if command_args.temp_output and model_name != 'ete':\n",
        "            with tempfile.NamedTemporaryFile() as temp_output_file:\n",
        "                run_treebank(mode, paths, treebank, short_name,\n",
        "                             temp_output_file.name, command_args, extra_args)\n",
        "        else:\n",
        "            run_treebank(mode, paths, treebank, short_name,\n",
        "                         None, command_args, extra_args)\n",
        "\n",
        "def run_eval_script(gold_conllu_file, system_conllu_file, evals=None):\n",
        "    \"\"\" Wrapper for lemma scorer. \"\"\"\n",
        "    gold_ud = ud_eval.load_conllu_file(gold_conllu_file)\n",
        "    system_ud = ud_eval.load_conllu_file(system_conllu_file)\n",
        "    evaluation = ud_eval.evaluate(gold_ud, system_ud)\n",
        "\n",
        "    if evals is None:\n",
        "        return ud_eval.build_evaluation_table(evaluation, verbose=True, counts=False)\n",
        "    else:\n",
        "        results = [evaluation[key].f1 for key in evals]\n",
        "        return \" \".join(\"{:.2f}\".format(100 * x) for x in results)\n",
        "\n",
        "def run_eval_script_tokens(eval_gold, eval_pred):\n",
        "    return run_eval_script(eval_gold, eval_pred, evals=[\"Tokens\", \"Sentences\", \"Words\"])\n",
        "\n",
        "def run_eval_script_mwt(eval_gold, eval_pred):\n",
        "    return run_eval_script(eval_gold, eval_pred, evals=[\"Words\"])\n",
        "\n",
        "def run_eval_script_pos(eval_gold, eval_pred):\n",
        "    return run_eval_script(eval_gold, eval_pred, evals=[\"UPOS\", \"XPOS\", \"UFeats\", \"AllTags\"])\n",
        "\n",
        "def run_eval_script_depparse(eval_gold, eval_pred):\n",
        "    return run_eval_script(eval_gold, eval_pred, evals=[\"UAS\", \"LAS\", \"CLAS\", \"MLAS\", \"BLEX\"])\n",
        "\n",
        "\n",
        "def find_wordvec_pretrain(language, default_pretrain):\n",
        "    pretrain_path = '{}/{}/pretrain/*.pt'.format(DEFAULT_MODEL_DIR, language)\n",
        "    pretrains = glob.glob(pretrain_path)\n",
        "    if len(pretrains) == 0:\n",
        "        # TODO: try to extract/remember the specific pretrain for the given model\n",
        "        # That would be a good way to archive which pretrains are used for which NER models, anyway\n",
        "        # For now, just download the default and use that\n",
        "        pretrain_package = default_pretrain.get(language, None)\n",
        "        if pretrain_package is None:\n",
        "            logger.warning(f\"Cannot figure out which pretrain to use for '{language}'.  Will download the default package and hope for the best\")\n",
        "            download(lang=language)\n",
        "        else:\n",
        "            logger.warning(f\"Missing pretrain for '{language}'.  Will download the default pretrain '{pretrain_package}'\")\n",
        "            download(lang=language, package=None, processors={\"pretrain\": pretrain_package})\n",
        "        pretrains = glob.glob(pretrain_path)\n",
        "    if len(pretrains) == 0:\n",
        "        raise FileNotFoundError(f\"Cannot find any pretrains in {pretrain_path}  Try 'stanza.download(\\\"{language}\\\")' to get a default pretrain or use --wordvec_pretrain_file to specify a .pt file to use\")\n",
        "    if len(pretrains) > 1:\n",
        "        default_pt = default_pretrain.get(language, None)\n",
        "        if default_pt is None:\n",
        "            raise FileNotFoundError(f\"Too many pretrains to choose from in {pretrain_path}  No default pretrain is specified for language {language}  Must specify an exact path to a --wordvec_pretrain_file\")\n",
        "        for pt_file in pretrains:\n",
        "            pt_name = os.path.split(pt_file)[1]\n",
        "            pt_name = os.path.splitext(pt_name)[0]\n",
        "            if pt_name == default_pt:\n",
        "                logger.info(f\"Using default pretrain for language, found in {pt_file}  To use a different pretrain, specify --wordvec_pretrain_file\")\n",
        "                return pt_file\n",
        "        raise FileNotFoundError(f\"Too many pretrains to choose from in {pretrain_path}  Could not find default pt {default_pt} for language {language}  Must specify an exact path to a --wordvec_pretrain_file\")\n",
        "    pt = pretrains[0]\n",
        "    logger.info(f\"Using pretrain found in {pt}  To use a different pretrain, specify --wordvec_pretrain_file\")\n",
        "    return pt\n",
        "\n",
        "def find_charlm_file(direction, language, charlm):\n",
        "    \"\"\"\n",
        "    Return the path to the forward or backward charlm if it exists for the given package\n",
        "\n",
        "    If we can figure out the package, but can't find it anywhere, we try to download it\n",
        "    \"\"\"\n",
        "    saved_path = 'saved_models/charlm/{}_{}_{}_charlm.pt'.format(language, charlm, direction)\n",
        "    if os.path.exists(saved_path):\n",
        "        logger.info(f'Using model {saved_path} for {direction} charlm')\n",
        "        return saved_path\n",
        "\n",
        "    resource_path = '{}/{}/{}_charlm/{}.pt'.format(DEFAULT_MODEL_DIR, language, direction, charlm)\n",
        "    if os.path.exists(resource_path):\n",
        "        logger.info(f'Using model {resource_path} for {direction} charlm')\n",
        "        return resource_path\n",
        "\n",
        "    try:\n",
        "        download(lang=language, package=None, processors={f\"{direction}_charlm\": charlm})\n",
        "        if os.path.exists(resource_path):\n",
        "            logger.info(f'Downloaded model, using model {resource_path} for {direction} charlm')\n",
        "            return resource_path\n",
        "    except ValueError as e:\n",
        "        # we're about to throw an error anyway\n",
        "        pass\n",
        "\n",
        "    raise FileNotFoundError(f\"Cannot find {direction} charlm in either {saved_path} or {resource_path}  Attempted downloading {charlm} but that did not work\")\n",
        "\n",
        "def build_charlm_args(language, charlm, base_args=True):\n",
        "    \"\"\"\n",
        "    If specified, return forward and backward charlm args\n",
        "    \"\"\"\n",
        "    if charlm:\n",
        "        forward = find_charlm_file('forward', language, charlm)\n",
        "        backward = find_charlm_file('backward', language, charlm)\n",
        "        char_args = ['--charlm_forward_file', forward,\n",
        "                     '--charlm_backward_file', backward]\n",
        "        if not base_args:\n",
        "            return char_args\n",
        "        return ['--charlm',\n",
        "                '--charlm_shorthand', f'{language}_{charlm}'] + char_args\n",
        "\n",
        "    return []\n",
        "\n",
        "def choose_charlm(language, dataset, charlm, language_charlms, dataset_charlms):\n",
        "    default_charlm = language_charlms.get(language, None)\n",
        "    specific_charlm = dataset_charlms.get(language, {}).get(dataset, None)\n",
        "\n",
        "    if charlm is None:\n",
        "        return None\n",
        "    elif charlm != \"default\":\n",
        "        return charlm\n",
        "    elif specific_charlm:\n",
        "        return specific_charlm\n",
        "    elif default_charlm:\n",
        "        return default_charlm\n",
        "    else:\n",
        "        return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pPIyy-1Xhrn",
        "outputId": "29d512b1-6c9a-4a86-bf9c-ea5bdb3059be"
      },
      "outputs": [],
      "source": [
        "%%writefile /content/stanza-train-br/stanza/stanza/utils/training/run_pos.py\n",
        "\n",
        "\n",
        "import logging\n",
        "import os\n",
        "\n",
        "from stanza.models import tagger\n",
        "\n",
        "from stanza.utils.training import common\n",
        "from stanza.utils.training.common import Mode\n",
        "\n",
        "logger = logging.getLogger('stanza')\n",
        "\n",
        "# TODO: move this somewhere common\n",
        "def wordvec_args(short_language):\n",
        "    if short_language in (\"cop\", \"orv\", \"pcm\", \"qtd\", \"swl\"):\n",
        "        # we couldn't find word vectors for these languages:\n",
        "        # coptic, naija, old russian, turkish german, swedish sign language\n",
        "        logger.warning(\"No known word vectors for language {}  If those vectors can be found, please update the training scripts.\".format(short_language))\n",
        "        return [\"--no_pretrain\"]\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "def pos_batch_size(short_name):\n",
        "    if short_name == 'de_hdt':\n",
        "        # 'UD_German-HDT'\n",
        "        return \"2000\"\n",
        "    elif short_name == 'hr_set':\n",
        "        # 'UD_Croatian-SET'\n",
        "        return \"3000\"\n",
        "    else:\n",
        "        return \"5000\"\n",
        "\n",
        "def run_treebank(mode, paths, treebank, short_name,\n",
        "                 temp_output_file, command_args, extra_args):\n",
        "    short_language = short_name.split(\"_\")[0]\n",
        "\n",
        "    pos_dir        = paths[\"POS_DATA_DIR\"]\n",
        "    train_file     = f\"{pos_dir}/{short_name}.train.in.conllu\"\n",
        "    train_gold_file= f\"{pos_dir}/{short_name}.train.gold.conllu\"\n",
        "    train_pred_file= temp_output_file if temp_output_file else f\"{pos_dir}/{short_name}.train.pred.conllu\"\n",
        "    dev_in_file    = f\"{pos_dir}/{short_name}.dev.in.conllu\"\n",
        "    dev_gold_file  = f\"{pos_dir}/{short_name}.dev.gold.conllu\"\n",
        "    dev_pred_file  = temp_output_file if temp_output_file else f\"{pos_dir}/{short_name}.dev.pred.conllu\"\n",
        "    test_in_file   = f\"{pos_dir}/{short_name}.test.in.conllu\"\n",
        "    test_gold_file = f\"{pos_dir}/{short_name}.test.gold.conllu\"\n",
        "    test_pred_file = temp_output_file if temp_output_file else f\"{pos_dir}/{short_name}.test.pred.conllu\"\n",
        "\n",
        "    if mode == Mode.TRAIN:\n",
        "        if not os.path.exists(train_file):\n",
        "            logger.error(\"TRAIN FILE NOT FOUND: %s ... skipping\" % train_file)\n",
        "            return\n",
        "\n",
        "        # some languages need reduced batch size\n",
        "        batch_size = pos_batch_size(short_name)\n",
        "\n",
        "        train_args = [\"--wordvec_dir\", paths[\"WORDVEC_DIR\"],\n",
        "                      \"--train_file\", train_file,\n",
        "                      \"--eval_file\", dev_in_file,\n",
        "                      \"--output_file\", dev_pred_file,\n",
        "                      \"--gold_file\", dev_gold_file,\n",
        "                      \"--batch_size\", batch_size,\n",
        "                      \"--lang\", short_language,\n",
        "                      \"--shorthand\", short_name,\n",
        "                      \"--mode\", \"train\"]\n",
        "        train_args = train_args + wordvec_args(short_language)\n",
        "        train_args = train_args + extra_args\n",
        "        logger.info(\"Running train POS for {} with args {}\".format(treebank, train_args))\n",
        "        tagger.main(train_args)\n",
        "    \n",
        "    if mode == Mode.SCORE_TRAIN:\n",
        "        train_pred_args = [\"--wordvec_dir\", paths[\"WORDVEC_DIR\"],\n",
        "                    \"--eval_file\", train_file,\n",
        "                    \"--output_file\", train_pred_file,\n",
        "                    \"--gold_file\", train_file,\n",
        "                    \"--lang\", short_language,\n",
        "                    \"--shorthand\", short_name,\n",
        "                    \"--mode\", \"predict\"]\n",
        "        train_pred_args = train_pred_args + wordvec_args(short_language)\n",
        "        train_pred_args = train_pred_args + extra_args\n",
        "        logger.info(\"Running train POS for {} with args {}\".format(treebank, train_pred_args))\n",
        "        tagger.main(train_pred_args)\n",
        "\n",
        "        results = common.run_eval_script_pos(train_file, train_pred_file)\n",
        "        logger.info(\"Finished running test set on\\n{}\\n{}\".format(treebank, results))\n",
        "\n",
        "    if mode == Mode.SCORE_DEV or mode == Mode.TRAIN:\n",
        "        dev_args = [\"--wordvec_dir\", paths[\"WORDVEC_DIR\"],\n",
        "                    \"--eval_file\", dev_in_file,\n",
        "                    \"--output_file\", dev_pred_file,\n",
        "                    \"--gold_file\", dev_gold_file,\n",
        "                    \"--lang\", short_language,\n",
        "                    \"--shorthand\", short_name,\n",
        "                    \"--mode\", \"predict\"]\n",
        "        dev_args = dev_args + wordvec_args(short_language)\n",
        "        dev_args = dev_args + extra_args\n",
        "        logger.info(\"Running dev POS for {} with args {}\".format(treebank, dev_args))\n",
        "        tagger.main(dev_args)\n",
        "\n",
        "        results = common.run_eval_script_pos(dev_gold_file, dev_pred_file)\n",
        "        logger.info(\"Finished running dev set on\\n{}\\n{}\".format(treebank, results))\n",
        "\n",
        "    if mode == Mode.SCORE_TEST:\n",
        "        test_args = [\"--wordvec_dir\", paths[\"WORDVEC_DIR\"],\n",
        "                    \"--eval_file\", test_in_file,\n",
        "                    \"--output_file\", test_pred_file,\n",
        "                    \"--gold_file\", test_gold_file,\n",
        "                    \"--lang\", short_language,\n",
        "                    \"--shorthand\", short_name,\n",
        "                    \"--mode\", \"predict\"]\n",
        "        test_args = test_args + wordvec_args(short_language)\n",
        "        test_args = test_args + extra_args\n",
        "        logger.info(\"Running test POS for {} with args {}\".format(treebank, test_args))\n",
        "        tagger.main(test_args)\n",
        "\n",
        "        results = common.run_eval_script_pos(test_gold_file, test_pred_file)\n",
        "        logger.info(\"Finished running test set on\\n{}\\n{}\".format(treebank, results))\n",
        "\n",
        "\n",
        "def main():\n",
        "    common.main(run_treebank, \"pos\", \"tagger\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIHKFHXFXuoF",
        "outputId": "963b7218-995d-4f38-b65f-f12a67b61a98"
      },
      "outputs": [],
      "source": [
        "DATA_ROOT=\"../data/processed\"\n",
        "%cd /content/stanza-train-br/stanza\n",
        "%env UDBASE=../data/udbase\n",
        "%env NERBASE=../data/nerbase\n",
        "%env TOKENIZE_DATA_DIR=$DATA_ROOT/tokenize\n",
        "%env MWT_DATA_DIR=$DATA_ROOT/mwt\n",
        "%env LEMMA_DATA_DIR=$DATA_ROOT/lemma\n",
        "%env POS_DATA_DIR=$DATA_ROOT/pos\n",
        "%env DEPPARSE_DATA_DIR=$DATA_ROOT/depparse\n",
        "%env ETE_DATA_DIR=$DATA_ROOT/ete\n",
        "%env NER_DATA_DIR=$DATA_ROOT/ner\n",
        "%env CHARLM_DATA_DIR=$DATA_ROOT/charlm\n",
        "%env WORDVEC_DIR=../data/wordvec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwCQ-k3siU8L",
        "outputId": "0494dad9-908a-4741-8e8d-15cbe9638cce"
      },
      "outputs": [],
      "source": [
        "for seed in range(42, 52):\n",
        "    ! python3 -m stanza.utils.training.run_pos UD_Portuguese-Porttinari --max_steps 1000 --force --seed {seed}\n",
        "    ! python3 -m stanza.utils.training.run_pos UD_Portuguese-Porttinari --score_test --save_output\n",
        "    ! python3 -m stanza.utils.training.run_pos UD_Portuguese-Porttinari --score_train --save_output\n",
        "    ! mv /content/stanza-train-br/data/processed/pos/pt_porttinari.test.pred.conllu /content/drive/MyDrive/Studies/Mestrado/Experimentos\\ \\Tagging\\ \\Porttinari-base/stanza/pt_porttinari_test_pred_{seed}.conllu\n",
        "    ! mv /content/stanza-train-br/data/processed/pos/pt_porttinari.train.pred.conllu /content/drive/MyDrive/Studies/Mestrado/Experimentos\\ \\Tagging\\ \\Porttinari-base/stanza/pt_porttinari_train_pred_{seed}.conllu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2lJ2i8nqZmi",
        "outputId": "8945aa16-f949-442a-f106-c6549e73f3b3"
      },
      "outputs": [],
      "source": [
        "! python3 -m stanza.utils.conll18_ud_eval \\\n",
        "    $DATA_ROOT/pos/pt_bosque.test.gold.conllu \\\n",
        "    $DATA_ROOT/pos/pt_bosque.test.pred.conllu \\\n",
        "    --verbose"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
