{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWEb0N9AM398"
      },
      "source": [
        "# CNCSR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEI--nnmM5vb"
      },
      "source": [
        "## Setting up CNCSR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oJoQ9q5Bq0v",
        "outputId": "17b1b2f4-2751-48e0-843c-b1fa4cdf0322"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/huberemanuel/subword-sequence-tagging.git\n",
        "! pip install -r subword-sequence-tagging/requirements.txt\n",
        "! cd subword-sequence-tagging/data && tar -xvf ud_1_2.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DuWwjVgEfnG",
        "outputId": "349cf4f9-db95-46fc-e48e-053e9d24b51e"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "mkdir data\n",
        "mkdir embeddings\n",
        "wget http://143.107.183.175:22980/download.php?file=embeddings/fasttext/skip_s300.zip -P data\n",
        "# cp /content/drive/MyDrive/Colab\\ Notebooks/resources/skip_s300.zip data/\n",
        "unzip data/skip_s300.zip -d embeddings\n",
        "\n",
        "# Porttinari-base\n",
        "git clone https://github.com/huberemanuel/UD_Portuguese-Porttinari.git\n",
        "cp UD_Portuguese-Porttinari/pt_porttinari-ud-train.conllu /content/subword-sequence-tagging/data/ud_1_2/train/pt.conllu\n",
        "cp UD_Portuguese-Porttinari/pt_porttinari-ud-dev.conllu /content/subword-sequence-tagging/data/ud_1_2/dev/pt.conllu\n",
        "cp UD_Portuguese-Porttinari/pt_porttinari-ud-test.conllu /content/subword-sequence-tagging/data/ud_1_2/test/pt.conllu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMktESZkHBg8"
      },
      "outputs": [],
      "source": [
        "! mkdir -p /content/subword-sequence-tagging/data/my_ud/train /content/subword-sequence-tagging/data/my_ud/dev /content/subword-sequence-tagging/data/my_ud/test\n",
        "! cp /content/UD_Portuguese-Porttinari/pt_porttinari-ud-train.conllu /content/subword-sequence-tagging/data/my_ud/train/pt.conll \n",
        "! cp /content/UD_Portuguese-Porttinari/pt_porttinari-ud-dev.conllu /content/subword-sequence-tagging/data/my_ud/dev/pt-ud.conll \n",
        "! cp /content/UD_Portuguese-Porttinari/pt_porttinari-ud-test.conllu /content/subword-sequence-tagging/data/my_ud/test/pt.conll! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b3xUmrlINOn",
        "outputId": "a5180d90-a180-4c85-d61c-87308625d29b"
      },
      "outputs": [],
      "source": [
        "! pip freeze | grep sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04oKr-4pIPhW",
        "outputId": "886eaab5-223d-4da3-ae96-2398fc53663b"
      },
      "outputs": [],
      "source": [
        "! pip install sentencepiece==0.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nOTvuMW4Br0",
        "outputId": "32361630-a1fc-45e3-b602-d84622b48eed"
      },
      "outputs": [],
      "source": [
        "%%writefile subword-sequence-tagging/trainer.py\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from bert_wrapper import Transformer as Bert\n",
        "from data import datasets\n",
        "from model import SequenceTagger\n",
        "from util import (\n",
        "    ConllScore,\n",
        "    EarlyStopping,\n",
        "    LossTrackers,\n",
        "    Score,\n",
        "    dump_args,\n",
        "    emb_layer,\n",
        "    get_logger,\n",
        "    get_optim,\n",
        "    json_load,\n",
        "    load_word2vec_file,\n",
        "    mkdir,\n",
        "    next_rundir,\n",
        "    save_model,\n",
        "    set_random_seed,\n",
        ")\n",
        "\n",
        "\n",
        "def load_dataset(conf, lang, bert=None):\n",
        "    if conf.best_vocab_size:\n",
        "        conf.vocab_size = json_load(conf.best_vocab_size_file)[conf.lang]\n",
        "    data = datasets[conf.dataset].load(conf, lang, bert=bert)\n",
        "    data.describe()\n",
        "    return data\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, conf):\n",
        "        self.conf = conf\n",
        "        self.device = torch.device(f\"cuda:{conf.gpu_id}\")\n",
        "        self.log = get_logger()\n",
        "        torch.set_printoptions(precision=8)\n",
        "        if conf.runid:\n",
        "            conf.rundir = mkdir(conf.outdir / conf.runid)\n",
        "        if not conf.rundir:\n",
        "            conf.rundir = next_rundir(conf.outdir, log=self.log)\n",
        "        self.rundir = conf.rundir\n",
        "        dump_args(conf, conf.rundir / \"conf.json\")\n",
        "        set_random_seed(conf.random_seed)\n",
        "        if self.conf.use_bert:\n",
        "            assert self.conf.lang in Bert.supported_langs, self.conf.lang\n",
        "            self.bert = Bert(self.conf.bert_model_name, device=self.device)\n",
        "        else:\n",
        "            self.bert = None\n",
        "        self.data = load_dataset(conf, conf.lang, bert=self.bert)\n",
        "        _data = [self.data]\n",
        "        for d in _data:\n",
        "            self.log.info(f\"{len(d.train_loader)} batches | bs {conf.batch_size}\")\n",
        "        self.model = self.get_model()\n",
        "        self.optimizer = get_optim(conf, self.model)\n",
        "        optimum = \"min\"\n",
        "        if conf.lr_scheduler == \"plateau\":\n",
        "            self.lr_scheduler = ReduceLROnPlateau(\n",
        "                self.optimizer, factor=0.1, patience=2, mode=optimum, verbose=True\n",
        "            )\n",
        "        elif conf.lr_scheduler:\n",
        "            raise ValueError(\"Unknown lr_scheduler: \" + conf.lr_scheduler)\n",
        "        self.losses = LossTrackers.from_names(\"loss\", log=self.log)\n",
        "        if self.main_lang_data.tag == \"ner\" or self.conf.dataset.startswith(\"sr3de\"):\n",
        "            if self.data.is_multilingual:\n",
        "                self.sentence_texts = {\n",
        "                    split_name: self.main_lang_data.token_texts(split_name)\n",
        "                    for split_name in [\"dev\", \"test\"]\n",
        "                }\n",
        "                self.conll_score = {\n",
        "                    lang: ConllScore(tag_enc=self.main_lang_data.tag_enc)\n",
        "                    for lang in self.data.dev\n",
        "                }\n",
        "                self.score = {\n",
        "                    lang: Score(\n",
        "                        \"f1\",\n",
        "                        save_model=False,\n",
        "                        log=self.log,\n",
        "                        score_func=self.conll_score[lang],\n",
        "                        add_mode=\"append\",\n",
        "                    )\n",
        "                    for lang in self.data.dev\n",
        "                }\n",
        "                self.avg_score = Score(\n",
        "                    \"avg_f1\", log=self.log, score_func=\"dummy\", add_mode=\"append\"\n",
        "                )\n",
        "            else:\n",
        "                self.sentence_texts = {\n",
        "                    split_name: self.main_lang_data.token_texts(split_name)[\n",
        "                        : conf.max_eval_inst\n",
        "                    ]\n",
        "                    for split_name in [\"dev\", \"test\"]\n",
        "                }\n",
        "                self.conll_score = ConllScore(tag_enc=self.main_lang_data.tag_enc)\n",
        "                self.score = Score(\n",
        "                    \"f1\", log=self.log, score_func=self.conll_score, add_mode=\"append\"\n",
        "                )\n",
        "        else:\n",
        "            if self.data.is_multilingual:\n",
        "                self.score = {\n",
        "                    lang: Score(\"acc\", log=self.log) for lang in self.data.dev\n",
        "                }\n",
        "                self.avg_score = Score(\n",
        "                    \"avg_acc\", log=self.log, score_func=\"dummy\", add_mode=\"append\"\n",
        "                )\n",
        "            else:\n",
        "                self.score = Score(\"acc\", log=self.log)\n",
        "        if conf.early_stop > 0:\n",
        "            score_optimum = (\n",
        "                \"max\"\n",
        "                if (\n",
        "                    self.conf.dataset.startswith(\"wikiannmulti\")\n",
        "                    or self.data.is_multilingual\n",
        "                )\n",
        "                else self.score.optimum\n",
        "            )\n",
        "            self.early_stop = EarlyStopping(\n",
        "                score_optimum,\n",
        "                min_delta=conf.early_stop_min_delta,\n",
        "                patience=conf.early_stop,\n",
        "            )\n",
        "        else:\n",
        "            self.early_stop = None\n",
        "        self.epoch = 0\n",
        "\n",
        "    def get_model(self):\n",
        "        ntags = self.data.tag_enc.nlabels\n",
        "        nshapes = self.data.shape_enc.nlabels\n",
        "        nchars = self.data.char_enc.nlabels\n",
        "        bpe_emb = emb_layer(\n",
        "            self.data.bpemb.vectors,\n",
        "            trainable=not self.conf.emb_fixed,\n",
        "            use_weights=not self.conf.emb_random_init,\n",
        "        )\n",
        "        if self.conf.use_fasttext:\n",
        "            fasttext_file = self.conf.fasttext_emb_file.format(\n",
        "                dataset=self.conf.dataset, lang=self.data.lang\n",
        "            )\n",
        "            fasttext_emb = emb_layer(\n",
        "                load_word2vec_file(fasttext_file, add_unk=True),\n",
        "                trainable=not self.conf.emb_fixed,\n",
        "                use_weights=not self.conf.emb_random_init,\n",
        "            )\n",
        "        else:\n",
        "            fasttext_emb = None\n",
        "        model = SequenceTagger(\n",
        "            bpe_emb,\n",
        "            ntags,\n",
        "            self.conf,\n",
        "            nchars=nchars,\n",
        "            nshapes=nshapes,\n",
        "            fasttext_emb=fasttext_emb,\n",
        "            bert=self.bert,\n",
        "            tag_enc=self.main_lang_data.tag_enc,\n",
        "        ).to(self.device)\n",
        "        self.log.info(f\"model repr dim: {model.repr_dim}\")\n",
        "        if self.conf.model_file:\n",
        "            self.log.info(f\"loading model {self.conf.model_file}\")\n",
        "            model.load_state_dict(torch.load(self.conf.model_file))\n",
        "            self.log.info(f\"loaded model {self.conf.model_file}\")\n",
        "        return model\n",
        "\n",
        "    def train(self, train_epoch, do_eval, do_test=None, eval_ds_name=None):\n",
        "        try:\n",
        "            for epoch in range(1, self.conf.max_epochs + 1):\n",
        "                self.epoch = epoch\n",
        "                self.model.train()\n",
        "                train_epoch(epoch=epoch)\n",
        "                self.losses.interval_end_log(epoch, ds_name=\"train\")\n",
        "                burnin_done = epoch >= self.conf.first_eval_epoch\n",
        "                if burnin_done and not epoch % self.conf.eval_every:\n",
        "                    score, preds, trues = self.do_eval(\n",
        "                        do_eval, epoch=epoch, eval_ds_name=eval_ds_name\n",
        "                    )\n",
        "                    if do_test:\n",
        "                        self.do_eval(do_test, epoch=epoch, eval_ds_name=\"test\")\n",
        "                    if score is not None and self.early_stop:\n",
        "                        if self.early_stop.step(score):\n",
        "                            if epoch >= self.conf.min_epochs:\n",
        "                                patience = self.early_stop.patience\n",
        "                                self.log.info(f\"Early stop after {patience} steps\")\n",
        "                                break\n",
        "        except KeyboardInterrupt:\n",
        "            self.log.info(\"Stopping training due to keyboard interrupt\")\n",
        "\n",
        "    def do_eval(self, eval_func, epoch=None, eval_ds_name=None):\n",
        "        self.model.eval()\n",
        "        cur_score, preds, trues = eval_func(epoch=epoch)\n",
        "        self.log_eval(ds_name=eval_ds_name, epoch=epoch)\n",
        "        if self.data.is_multilingual:\n",
        "            return self.avg_score.current\n",
        "        return self.score.current, preds, trues\n",
        "\n",
        "    def log_eval(self, ds_name=None, epoch=None):\n",
        "        self.losses.interval_end(ds_name=ds_name)\n",
        "        if self.data.is_multilingual:\n",
        "            for lang in getattr(self.data, ds_name):\n",
        "                if hasattr(self, \"conll_score\"):\n",
        "                    self.conll_score[lang].sentences = self.sentence_texts[ds_name][\n",
        "                        lang\n",
        "                    ]\n",
        "                    fname = f\"{epoch}.{ds_name}.{lang}.conll\"\n",
        "                    self.conll_score[lang].outfile = self.rundir / fname\n",
        "                self.score[lang].update()\n",
        "            avg_score = np.average([score.current for score in self.score.values()])\n",
        "            self.avg_score.update_log(\n",
        "                model=self.model, rundir=self.rundir, epoch=epoch, score=avg_score\n",
        "            )\n",
        "        else:\n",
        "            if hasattr(self, \"conll_score\"):\n",
        "                self.conll_score.sentences = self.sentence_texts[ds_name]\n",
        "                fname = f\"{epoch}.{ds_name}.conll\"\n",
        "                self.conll_score.outfile = self.rundir / fname\n",
        "            self.score.update_log(self.model, self.rundir, epoch)\n",
        "\n",
        "    def save_model(self):\n",
        "        model_file = self.rundir / f\"model.e{self.epoch}.pt\"\n",
        "        save_model(self.model, model_file, self.log)\n",
        "\n",
        "    @property\n",
        "    def main_lang_data(self):\n",
        "        return self.data[0] if isinstance(self.data, list) else self.data\n",
        "\n",
        "    @property\n",
        "    def batch_iter_train_multilang(self):\n",
        "        main_lang_len = len(self.data[0].train_loader)\n",
        "        max_sim_lang_len = int(self.conf.sim_lang_ratio * main_lang_len)\n",
        "\n",
        "        def get_sim_lang_len(i):\n",
        "            sim_lang_len = len(self.data[i].train_loader)\n",
        "            return min(sim_lang_len, max_sim_lang_len)\n",
        "\n",
        "        lang_idxs = [\n",
        "            i\n",
        "            for i, data in enumerate(self.data)\n",
        "            for _ in range(main_lang_len if i == 0 else get_sim_lang_len(i))\n",
        "        ]\n",
        "        random.shuffle(lang_idxs)\n",
        "        iters = [data.batch_iter_train for data in self.data]\n",
        "        return ((i, next(iters[i])) for i in lang_idxs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sgli2ujm7qkY",
        "outputId": "c9161110-88ac-4009-c30d-312582919f5d"
      },
      "outputs": [],
      "source": [
        "%%writefile /content/subword-sequence-tagging/main.py\n",
        "from copy import deepcopy\n",
        "from functools import partial\n",
        "from itertools import islice\n",
        "\n",
        "import torch\n",
        "\n",
        "from argparser import get_args\n",
        "from eval import save_conllu\n",
        "from trainer import Trainer\n",
        "\n",
        "\n",
        "def train(conf):\n",
        "    t = Trainer(conf)\n",
        "    optim = t.optimizer\n",
        "    model = t.model\n",
        "\n",
        "    def train_epoch(*args, **kwargs):\n",
        "        for i, batch in enumerate(t.data.batch_iter_train):\n",
        "            optim.zero_grad()\n",
        "            tag_true = batch[\"token\"][3]\n",
        "            _, loss = model(batch, tag_true=tag_true)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            t.losses.append(loss)\n",
        "        if hasattr(t, \"lr_scheduler\"):\n",
        "            t.lr_scheduler.step(t.losses[0].current)\n",
        "\n",
        "    def train_epoch_multilang(*args, **kwargs):\n",
        "        for i, (lang_idx, batch) in enumerate(t.batch_iter_train_multilang):\n",
        "            optim.zero_grad()\n",
        "            tag_true = batch[\"token\"][3]\n",
        "            _, loss = model(batch, tag_true=tag_true, lang_idx=lang_idx)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            t.losses.append(loss)\n",
        "\n",
        "    def do_eval(ds_iter, *args, **kwargs):\n",
        "        preds = []\n",
        "        trues = []\n",
        "        for batch in islice(ds_iter(), conf.max_eval_inst):\n",
        "            sorted_len, sort_idx, tag_true = batch[\"token\"][1:4]\n",
        "            tag_pred, loss = model(batch, tag_true=tag_true)\n",
        "            unsort_idx = torch.sort(sort_idx)[1]\n",
        "            for l, true, pred in zip(\n",
        "                sorted_len[unsort_idx], tag_pred[unsort_idx], tag_true[unsort_idx]\n",
        "            ):\n",
        "                t.score.add(pred[:l], true[:l])\n",
        "                preds.append(pred[:l])\n",
        "                trues.append(true[:l])\n",
        "        return (t.score.current, preds, trues)\n",
        "\n",
        "    def do_eval_multi(ds_iter, *args, **kwargs):\n",
        "        for lang, ds in ds_iter():\n",
        "            for batch in ds:\n",
        "                sorted_len, sort_idx, tag_true = batch[\"token\"][1:4]\n",
        "                tag_pred, loss = model(batch, tag_true=tag_true)\n",
        "                unsort_idx = torch.sort(sort_idx)[1]\n",
        "                for l, true, pred in zip(\n",
        "                    sorted_len[unsort_idx], tag_pred[unsort_idx], tag_true[unsort_idx]\n",
        "                ):\n",
        "                    t.score[lang].add(pred[:l], true[:l])\n",
        "        return t.avg_score.current\n",
        "\n",
        "    _train_epoch = train_epoch\n",
        "    if t.data.is_multilingual:\n",
        "        _do_eval = partial(do_eval_multi, lambda: t.data.iter_dev)\n",
        "        do_test = partial(do_eval_multi, lambda: t.data.iter_test)\n",
        "    else:\n",
        "        _do_eval = partial(do_eval, lambda: t.main_lang_data.iter_dev)\n",
        "        do_test = partial(do_eval, lambda: t.main_lang_data.iter_test)\n",
        "    _do_test = do_test if conf.test_every_eval else None\n",
        "    t.train(_train_epoch, _do_eval, do_test=_do_test, eval_ds_name=\"dev\")\n",
        "    if t.data.is_multilingual:\n",
        "        score = t.avg_score\n",
        "    else:\n",
        "        score = t.score\n",
        "    conf.model_file = score.best_model\n",
        "    test_score = test(conf)\n",
        "    if t.data.is_multilingual:\n",
        "        test_score, lang_scores = test_score\n",
        "        for lang, lang_score in lang_scores.items():\n",
        "            t.log.info(f\"{lang} score: {lang_score.current:.4}\")\n",
        "    t.log.info(f\"final score: {test_score:.4}\")\n",
        "\n",
        "\n",
        "def test(conf, model=None):\n",
        "    t = Trainer(conf)\n",
        "    if model is None:\n",
        "        model = t.model\n",
        "\n",
        "    if t.data.is_multilingual:\n",
        "\n",
        "        def do_test(*args, **kwargs):\n",
        "            for lang, ds in t.data.iter_test:\n",
        "                for batch in ds:\n",
        "                    sorted_len, sort_idx, tag_true = batch[\"token\"][1:4]\n",
        "                    tag_pred, loss = model(batch, tag_true=tag_true)\n",
        "                    unsort_idx = torch.sort(sort_idx)[1]\n",
        "                    for l, true, pred in zip(\n",
        "                        sorted_len[unsort_idx],\n",
        "                        tag_pred[unsort_idx],\n",
        "                        tag_true[unsort_idx],\n",
        "                    ):\n",
        "                        t.score[lang].add(pred[:l], true[:l])\n",
        "            return t.avg_score.current\n",
        "\n",
        "    else:\n",
        "\n",
        "        def do_test(*args, **kwargs):\n",
        "            preds = []\n",
        "            trues = []\n",
        "            for batch in islice(t.main_lang_data.iter_test, conf.max_eval_inst):\n",
        "                sorted_len, sort_idx, tag_true = batch[\"token\"][1:4]\n",
        "                tag_pred, loss = model(batch, tag_true=tag_true)\n",
        "                unsort_idx = torch.sort(sort_idx)[1]\n",
        "                for l, true, pred in zip(\n",
        "                    sorted_len[unsort_idx], tag_pred[unsort_idx], tag_true[unsort_idx]\n",
        "                ):\n",
        "                    t.score.add(pred[:l], true[:l])\n",
        "                    preds.append(pred[:l])\n",
        "                    trues.append(true[:l])\n",
        "            return (t.score.current, preds, trues)\n",
        "\n",
        "    score, preds, trues = t.do_eval(do_test, eval_ds_name=\"test\")\n",
        "\n",
        "    test_dataset = deepcopy(t.data.test_raw)\n",
        "    a = deepcopy(test_dataset)\n",
        "    diff = 0\n",
        "    i = 0\n",
        "    for sent, sent_pred, sent_true in zip(test_dataset, preds, trues):\n",
        "        sent_pred = t.data.tag_enc.inverse_transform(sent_pred)\n",
        "        sent_true = t.data.tag_enc.inverse_transform(sent_true)\n",
        "        j = 0\n",
        "        for token, pred_tag, gold_tag in zip(sent, sent_pred, sent_true):\n",
        "            # Someday I will understand this\n",
        "            test_dataset[i][j][\"upos\"] = gold_tag\n",
        "            if pred_tag != gold_tag:\n",
        "                diff += 1\n",
        "                t.log.info(\"{} - {}\".format(pred_tag, gold_tag))\n",
        "            j += 1\n",
        "        i += 1\n",
        "    t.log.info(\"Total diff tokens: {}\".format(diff))\n",
        "    t.log.info(\"---- {}\".format(a == test_dataset))\n",
        "    save_conllu(t.data.test_raw, rundir=\".\", eval_name=\"gold\")\n",
        "    save_conllu(test_dataset, rundir=\".\", eval_name=\"pred\")\n",
        "\n",
        "    if t.data.is_multilingual:\n",
        "        avg_score = score\n",
        "        lang_scores = t.score\n",
        "        for lang, lang_score in lang_scores.items():\n",
        "            t.log.info(f\"{lang} score: {lang_score.current:.4}\")\n",
        "        t.log.info(f\"avg score: {avg_score:.4}\")\n",
        "        return avg_score, lang_scores\n",
        "    return score\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    conf = get_args()\n",
        "    conf.bpemb_lang = conf.lang\n",
        "    globals()[conf.command.replace(\"-\", \"_\")](conf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvt9RSlV8m0y"
      },
      "outputs": [],
      "source": [
        "!  rm -rf /content/subword-sequence-tagging/out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuz9mrLtCsE9",
        "outputId": "15d2ff93-11e6-4bfc-af3c-adc51c33e469"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "# Execute 10 experiments\n",
        "for seed in range(42, 42 + 10):\n",
        "    ! rm -rf /content/subword-sequence-tagging/out\n",
        "    ! cd subword-sequence-tagging && python main.py train \\\n",
        "        --dataset ud_1_2 \\\n",
        "        --lang pt \\\n",
        "        --tag upostag \\\n",
        "        --use-char \\\n",
        "        --use-bpe \\\n",
        "        --use-meta-rnn \\\n",
        "        --best-vocab-size \\\n",
        "        --char-emb-dim 50 \\\n",
        "        --char-nhidden 256 \\\n",
        "        --bpe-nhidden 256 \\\n",
        "        --meta-nhidden 256 \\\n",
        "        --dropout 0.2 \\\n",
        "        --random-seed {seed}\n",
        "\n",
        "    model_path = glob.glob(\"/content/subword-sequence-tagging/out/0/acc*\")[0]\n",
        "\n",
        "    ! cd subword-sequence-tagging && python main.py test \\\n",
        "        --dataset ud_1_2 \\\n",
        "        --lang pt \\\n",
        "        --tag upostag \\\n",
        "        --model-file {model_path} \\\n",
        "        --use-char \\\n",
        "        --use-bpe \\\n",
        "        --use-meta-rnn \\\n",
        "        --best-vocab-size \\\n",
        "        --char-emb-dim 50 \\\n",
        "        --char-nhidden 256 \\\n",
        "        --bpe-nhidden 256 \\\n",
        "        --meta-nhidden 256 \\\n",
        "        --dropout 0.2\n",
        "\n",
        "    ! mkdir logs_{seed}\n",
        "    ! cd /content/subword-sequence-tagging && mv *.conllu ../logs_{seed}\n",
        "    ! cd /content/subword-sequence-tagging && mv {model_path} ../logs_{seed}\n",
        "    ! zip -r -9 logs_{seed}.zip logs_{seed}\n",
        "    ! mv logs_{seed}.zip \"/content/drive/MyDrive/Studies/Mestrado/Experimentos Tagging Porttinari-base/cncsr\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
